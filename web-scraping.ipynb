{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Mining and Applied NLP (44-620)\n",
    "\n",
    "## Web Scraping and NLP with Requests, BeautifulSoup, and spaCy\n",
    "\n",
    "### Student Name: Carlos Montoya III\n",
    "#### Repo url: https://github.com/carlosmontoya3/web-scraping\n",
    "\n",
    "Perform the tasks described in the Markdown cells below.  When you have completed the assignment make sure your code cells have all been run (and have output beneath them) and ensure you have committed and pushed ALL of your changes to your assignment repository.\n",
    "\n",
    "Every question that requires you to write code will have a code cell underneath it; you may either write your entire solution in that cell or write it in a python file (`.py`), then import and run the appropriate code to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "annotated-types           0.6.0\n",
      "anyio                     4.3.0\n",
      "appnope                   0.1.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "Babel                     2.14.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "blis                      0.7.11\n",
      "catalogue                 2.0.10\n",
      "certifi                   2024.2.2\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "cloudpathlib              0.16.0\n",
      "comm                      0.2.2\n",
      "confection                0.1.4\n",
      "contourpy                 1.2.1\n",
      "cycler                    0.12.1\n",
      "cymem                     2.0.8\n",
      "debugpy                   1.8.1\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "en-core-web-sm            3.7.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.1\n",
      "fonttools                 4.51.0\n",
      "fqdn                      1.5.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "idna                      3.7\n",
      "ipykernel                 6.29.4\n",
      "ipython                   8.23.0\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.3\n",
      "json5                     0.9.25\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.21.1\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.1\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.1.6\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.26.0\n",
      "kiwisolver                1.4.5\n",
      "langcodes                 3.3.0\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.8.4\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "murmurhash                1.0.10\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.3\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 24.0\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    10.3.0\n",
      "pip                       24.0\n",
      "platformdirs              4.2.0\n",
      "preshed                   3.0.9\n",
      "prometheus_client         0.20.0\n",
      "prompt-toolkit            3.0.43\n",
      "psutil                    5.9.8\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pyarrow                   15.0.2\n",
      "pycparser                 2.22\n",
      "pydantic                  2.7.0\n",
      "pydantic_core             2.18.1\n",
      "Pygments                  2.17.2\n",
      "pyparsing                 3.1.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "referencing               0.34.0\n",
      "requests                  2.31.0\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.18.0\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                69.5.1\n",
      "six                       1.16.0\n",
      "smart-open                6.4.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.5\n",
      "spacy                     3.7.4\n",
      "spacy-legacy              3.0.12\n",
      "spacy-loggers             1.0.5\n",
      "srsly                     2.4.8\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "thinc                     8.2.3\n",
      "tinycss2                  1.2.1\n",
      "tornado                   6.4\n",
      "tqdm                      4.66.2\n",
      "traitlets                 5.14.2\n",
      "typer                     0.9.4\n",
      "types-python-dateutil     2.9.0.20240316\n",
      "typing_extensions         4.11.0\n",
      "tzdata                    2024.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.1\n",
      "wasabi                    1.1.2\n",
      "wcwidth                   0.2.13\n",
      "weasel                    0.3.4\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.7.0\n",
      "wheel                     0.43.0\n",
      "All prereqs installed.\n"
     ]
    }
   ],
   "source": [
    "# Create and activate a Python virtual environment. \n",
    "# Before starting the project, try all these imports FIRST\n",
    "# Address any errors you get running this code cell \n",
    "# by installing the necessary packages into your active Python environment.\n",
    "# Try to resolve issues using your materials and the web.\n",
    "# If that doesn't work, ask for help in the discussion forums.\n",
    "# You can't complete the exercises until you import these - start early! \n",
    "# We also import pickle and Counter (included in the Python Standard Library).\n",
    "\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import requests\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip list\n",
    "\n",
    "print('All prereqs installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code that extracts the article html from https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/ and dumps it to a .pkl (or other appropriate file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article HTML extracted and saved to 'article_html.pkl'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://web.archive.org/web/20210327165005/https://hackaday.com/2021/03/22/how-laser-headlights-work/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    article_content = soup.find(\"article\")\n",
    "    article_html = str(article_content)\n",
    "    \n",
    "    with open(\"article_html.pkl\", \"wb\") as file:\n",
    "        pickle.dump(article_html, file)\n",
    "        \n",
    "    print(\"Article HTML extracted and saved to 'article_html.pkl'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read in your article's html source from the file you created in question 1 and print it's text (use `.get_text()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "How Laser Headlights Work\n",
      "\n",
      "\n",
      "                130 Comments            \n",
      "\n",
      "by:\n",
      "Lewin Day\n",
      "\n",
      "\n",
      "\n",
      "March 22, 2021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "When we think about the onward march of automotive technology, headlights aren’t usually the first thing that come to mind. Engines, fuel efficiency, and the switch to electric power are all more front of mind. However, that doesn’t mean there aren’t thousands of engineers around the world working to improve the state of the art in automotive lighting day in, day out.\n",
      "Sealed beam headlights gave way to more modern designs once regulations loosened up, while bulbs moved from simple halogens to xenon HIDs and, more recently, LEDs. Now, a new technology is on the scene, with lasers!\n",
      "\n",
      "Laser Headlights?!\n",
      "BWM’s prototype laser headlight assemblies undergoing testing.\n",
      "The first image brought to mind by the phrase “laser headlights” is that of laser beams firing out the front of an automobile. Obviously, coherent beams of monochromatic light would make for poor illumination outside of a very specific spot quite some distance away. Thankfully for our eyes, laser headlights don’t work in this way at all.\n",
      "Instead, laser headlights consist of one or more solid state laser diodes mounted inside the headlight. These blue lasers are fired at a yellow phosphor, similar to that used in white LEDs. This produces a powerful, vibrant white light that can then be bounced off reflectors and out of the headlights towards the road. Laser headlights built in this way have several benefits. They’re more energy efficient than LEDs that put out the same amount of light, while also being more space efficient, too.\n",
      "BWM’s futuristic i8 was one of the first vehicles to ship with laser headlight technology.\n",
      "Laser headlights are still a nascent technology, thus far only appearing in a few BMW, Audi, and other select vehicles. BMW’s technology was developed in partnership with lighting experts OSRAM. In practice, a regular LED low-beam lamp is used, with the laser used to create an incredibly bright and focused spot, used for high-beams. This can provide illumination out to 600 meters ahead of the vehicle, double that of conventional LED high beams. The lights use indium gallium nitride diode lasers that were originally used in projectors, with power levels above 1 watt. One of the challenges in implementing such technology in an automotive environment is the need for it to operate at temperature extremes. While research lasers and laser pointers may primarily be used at typical room temperatures, automotive headlights must be able to withstand everything from 40 degrees below zero up to 50 degrees C. Thankfully, the laser’s high efficiency means it doesn’t have huge heat output of its own to further complicate things. Other engineering challenges involve tailoring the optics package for the rough-and-tumble, high vibration environment found in the automotive application. It’s also important to ensure, as with any such device, that the end user can’t be exposed to harmful laser radiation in the event of accident or malfunction.\n",
      "Tearing Down the Laser Headlight\n",
      "A marketing image showing the construction of an aftermarket LED/laser headlight. We’d take the laser power with a grain of salt — it’s difficult to imagine a 10 W laser shining directly on some small LEDs without melting a hole through the board in short order.\n",
      "An aftermarket has sprung up too, with delightfully innovative designs. Combined laser/LED headlights are readily available on Alibaba, designed as a drop in replacement for projector lamps on existing vehicles. These often use an LED low-beam, and a combined LED/laser high beam, where the laser diode shoots directly at the LED phosphor to excite it further, rather than using its own. These units often also come with fan cooling to keep the laser and LEDs below their maximum operational temperature. Such developments are exciting, though it’s important to be wary of the performance of unknown aftermarket headlights. Many aftermarket LED headlight “upgrades” fail to pass muster when it comes to real-world performance, and there’s no reason to believe hybrid LED/laser designs will be any different. We’d love to pass a selection of these parts through a full IIHS test protocol, but that’s sadly beyond the scope (and budget!) of this article.\n",
      "However, [mikeselectricstuff] has happened to lay his hands on both the BMW and aftermarket parts, tearing them all down in his workshop to see what makes them tick. The differences are multitude when laid bare on the bench. The AliExpress part is relatively simple, wired up no differently from a regular headlight. Interestingly, however, the laser high-beam circuit runs all the time in these parts. To prevent blinding other road users, a shutter is kept in place to block the light, which is moved out of the way with a solenoid when the driver turns on the high beam switch.\n",
      "Where the aftermarket part is a little out of left field, the BMW design is another thing entirely. The cutting-edge headlights are hooked up with multiple connectors and over 30 conductors, with much of the driver electronics living in an external controller. Much of this is to drive the various LEDs and stepper motors for slewing the headlights when steering. However, the laser assembly brings its own complexities. Twin light sensors are built inside to monitor the laser beam, and a special metal blocking arm sits directly in front of the diode, presumably to stop the laser light leaving the headlight in the event the phosphor coating burns through. It’s truly wild to get a look inside a modern luxury car’s headlight and see just how far we’ve come from the old days of simple sealed beams.\n",
      "Cost Versus Performance\n",
      "Despite the efficiency gains available, the technology remains expensive. Powerful laser diodes don’t come cheap, after all. However, as the technology trickles down to lower-end models, it’s likely that we could see economies of scale change that for the better. Indeed, if national authorities begin to demand higher performance headlights as standard, we could see laser headlights become the norm, rather than an expensive luxury. The technology could naturally be applied to home and commercial lighting, too — though we suspect the potential gains are limited enough that LED lighting will remain the norm for some time to come.\n",
      "The high light output of laser headlights in a compact package allows engineers greater freedom when designing the front-end of a car.\n",
      "As it currently stands, much of the appeal of the new technology is about the packaging benefits, which allow automotive designers greater freedom around the headlight area. Such concerns are less of a factor when it comes to light fittings in the home or office, or indeed, on lower-end automobiles. Regardless, it’s an exciting new application for lasers and one we’ll be sure to see more of in the future.\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posted in car hacks, Engineering, Featured, Laser Hacks, SliderTagged laser, laser headlight, laser headlights, light \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the HTML content from the saved file\n",
    "try:\n",
    "    with open('article_html.pkl', 'rb') as file:\n",
    "        article_html = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please make sure the file 'article_html.pkl' exists.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(article_html, 'html.parser')\n",
    "\n",
    "# Extract text from HTML and print it\n",
    "article_text = soup.get_text()\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent tokens (converted to lower case).  Print the common tokens with an appropriate label.  Additionally, print the tokens their frequencies (with appropriate labels). Make sure to remove things we don't care about (punctuation, stopwords, whitespace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Please make sure the file 'article_text.pkl' exists.\n",
      "Most common tokens:\n",
      "laser: 35\n",
      "headlights: 19\n",
      "headlight: 11\n",
      "technology: 10\n",
      "led: 10\n",
      "\n",
      "All tokens with frequencies:\n",
      "laser: 35\n",
      "headlights: 19\n",
      "work: 2\n",
      "comments: 1\n",
      "lewin: 1\n",
      "day: 3\n",
      "march: 2\n",
      "think: 1\n",
      "onward: 1\n",
      "automotive: 6\n",
      "technology: 10\n",
      "usually: 1\n",
      "thing: 2\n",
      "come: 5\n",
      "mind: 3\n",
      "engines: 1\n",
      "fuel: 1\n",
      "efficiency: 3\n",
      "switch: 2\n",
      "electric: 1\n",
      "power: 3\n",
      "mean: 1\n",
      "thousands: 1\n",
      "engineers: 2\n",
      "world: 2\n",
      "working: 1\n",
      "improve: 1\n",
      "state: 2\n",
      "art: 1\n",
      "lighting: 4\n",
      "sealed: 2\n",
      "beam: 7\n",
      "gave: 1\n",
      "way: 4\n",
      "modern: 2\n",
      "designs: 3\n",
      "regulations: 1\n",
      "loosened: 1\n",
      "bulbs: 1\n",
      "moved: 2\n",
      "simple: 3\n",
      "halogens: 1\n",
      "xenon: 1\n",
      "hids: 1\n",
      "recently: 1\n",
      "leds: 6\n",
      "new: 3\n",
      "scene: 1\n",
      "lasers: 5\n",
      "bwm: 2\n",
      "prototype: 1\n",
      "headlight: 11\n",
      "assemblies: 1\n",
      "undergoing: 1\n",
      "testing: 1\n",
      "image: 2\n",
      "brought: 1\n",
      "phrase: 1\n",
      "beams: 5\n",
      "firing: 1\n",
      "automobile: 1\n",
      "obviously: 1\n",
      "coherent: 1\n",
      "monochromatic: 1\n",
      "light: 9\n",
      "poor: 1\n",
      "illumination: 2\n",
      "outside: 1\n",
      "specific: 1\n",
      "spot: 2\n",
      "distance: 1\n",
      "away: 1\n",
      "thankfully: 2\n",
      "eyes: 1\n",
      "instead: 1\n",
      "consist: 1\n",
      "solid: 1\n",
      "diodes: 2\n",
      "mounted: 1\n",
      "inside: 3\n",
      "blue: 1\n",
      "fired: 1\n",
      "yellow: 1\n",
      "phosphor: 3\n",
      "similar: 1\n",
      "white: 2\n",
      "produces: 1\n",
      "powerful: 2\n",
      "vibrant: 1\n",
      "bounced: 1\n",
      "reflectors: 1\n",
      "road: 2\n",
      "built: 2\n",
      "benefits: 2\n",
      "energy: 1\n",
      "efficient: 2\n",
      "space: 1\n",
      "futuristic: 1\n",
      "vehicles: 3\n",
      "ship: 1\n",
      "nascent: 1\n",
      "far: 2\n",
      "appearing: 1\n",
      "bmw: 4\n",
      "audi: 1\n",
      "select: 1\n",
      "developed: 1\n",
      "partnership: 1\n",
      "experts: 1\n",
      "osram: 1\n",
      "practice: 1\n",
      "regular: 2\n",
      "led: 10\n",
      "low: 2\n",
      "lamp: 1\n",
      "create: 1\n",
      "incredibly: 1\n",
      "bright: 1\n",
      "focused: 1\n",
      "high: 8\n",
      "provide: 1\n",
      "meters: 1\n",
      "ahead: 1\n",
      "vehicle: 1\n",
      "double: 1\n",
      "conventional: 1\n",
      "lights: 1\n",
      "use: 2\n",
      "indium: 1\n",
      "gallium: 1\n",
      "nitride: 1\n",
      "diode: 3\n",
      "originally: 1\n",
      "projectors: 1\n",
      "levels: 1\n",
      "watt: 1\n",
      "challenges: 2\n",
      "implementing: 1\n",
      "environment: 2\n",
      "need: 1\n",
      "operate: 1\n",
      "temperature: 2\n",
      "extremes: 1\n",
      "research: 1\n",
      "pointers: 1\n",
      "primarily: 1\n",
      "typical: 1\n",
      "room: 1\n",
      "temperatures: 1\n",
      "able: 1\n",
      "withstand: 1\n",
      "degrees: 2\n",
      "zero: 1\n",
      "means: 1\n",
      "huge: 1\n",
      "heat: 1\n",
      "output: 2\n",
      "complicate: 1\n",
      "things: 1\n",
      "engineering: 2\n",
      "involve: 1\n",
      "tailoring: 1\n",
      "optics: 1\n",
      "package: 2\n",
      "rough: 1\n",
      "tumble: 1\n",
      "vibration: 1\n",
      "found: 1\n",
      "application: 2\n",
      "important: 2\n",
      "ensure: 1\n",
      "device: 1\n",
      "end: 4\n",
      "user: 1\n",
      "exposed: 1\n",
      "harmful: 1\n",
      "radiation: 1\n",
      "event: 2\n",
      "accident: 1\n",
      "malfunction: 1\n",
      "tearing: 2\n",
      "marketing: 1\n",
      "showing: 1\n",
      "construction: 1\n",
      "aftermarket: 6\n",
      "grain: 1\n",
      "salt: 1\n",
      "difficult: 1\n",
      "imagine: 1\n",
      "w: 1\n",
      "shining: 1\n",
      "directly: 3\n",
      "small: 1\n",
      "melting: 1\n",
      "hole: 1\n",
      "board: 1\n",
      "short: 1\n",
      "order: 1\n",
      "sprung: 1\n",
      "delightfully: 1\n",
      "innovative: 1\n",
      "combined: 2\n",
      "readily: 1\n",
      "available: 2\n",
      "alibaba: 1\n",
      "designed: 1\n",
      "drop: 1\n",
      "replacement: 1\n",
      "projector: 1\n",
      "lamps: 1\n",
      "existing: 1\n",
      "shoots: 1\n",
      "excite: 1\n",
      "units: 1\n",
      "fan: 1\n",
      "cooling: 1\n",
      "maximum: 1\n",
      "operational: 1\n",
      "developments: 1\n",
      "exciting: 2\n",
      "wary: 1\n",
      "performance: 4\n",
      "unknown: 1\n",
      "upgrades: 1\n",
      "fail: 1\n",
      "pass: 2\n",
      "muster: 1\n",
      "comes: 2\n",
      "real: 1\n",
      "reason: 1\n",
      "believe: 1\n",
      "hybrid: 1\n",
      "different: 1\n",
      "love: 1\n",
      "selection: 1\n",
      "parts: 3\n",
      "iihs: 1\n",
      "test: 1\n",
      "protocol: 1\n",
      "sadly: 1\n",
      "scope: 1\n",
      "budget: 1\n",
      "article: 1\n",
      "mikeselectricstuff: 1\n",
      "happened: 1\n",
      "lay: 1\n",
      "hands: 1\n",
      "workshop: 1\n",
      "makes: 1\n",
      "tick: 1\n",
      "differences: 1\n",
      "multitude: 1\n",
      "laid: 1\n",
      "bare: 1\n",
      "bench: 1\n",
      "aliexpress: 1\n",
      "relatively: 1\n",
      "wired: 1\n",
      "differently: 1\n",
      "interestingly: 1\n",
      "circuit: 1\n",
      "runs: 1\n",
      "time: 2\n",
      "prevent: 1\n",
      "blinding: 1\n",
      "users: 1\n",
      "shutter: 1\n",
      "kept: 1\n",
      "place: 1\n",
      "block: 1\n",
      "solenoid: 1\n",
      "driver: 2\n",
      "turns: 1\n",
      "little: 1\n",
      "left: 1\n",
      "field: 1\n",
      "design: 1\n",
      "entirely: 1\n",
      "cutting: 1\n",
      "edge: 1\n",
      "hooked: 1\n",
      "multiple: 1\n",
      "connectors: 1\n",
      "conductors: 1\n",
      "electronics: 1\n",
      "living: 1\n",
      "external: 1\n",
      "controller: 1\n",
      "drive: 1\n",
      "stepper: 1\n",
      "motors: 1\n",
      "slewing: 1\n",
      "steering: 1\n",
      "assembly: 1\n",
      "brings: 1\n",
      "complexities: 1\n",
      "twin: 1\n",
      "sensors: 1\n",
      "monitor: 1\n",
      "special: 1\n",
      "metal: 1\n",
      "blocking: 1\n",
      "arm: 1\n",
      "sits: 1\n",
      "presumably: 1\n",
      "stop: 1\n",
      "leaving: 1\n",
      "coating: 1\n",
      "burns: 1\n",
      "truly: 1\n",
      "wild: 1\n",
      "look: 1\n",
      "luxury: 2\n",
      "car: 3\n",
      "old: 1\n",
      "days: 1\n",
      "cost: 1\n",
      "versus: 1\n",
      "despite: 1\n",
      "gains: 2\n",
      "remains: 1\n",
      "expensive: 2\n",
      "cheap: 1\n",
      "trickles: 1\n",
      "lower: 2\n",
      "models: 1\n",
      "likely: 1\n",
      "economies: 1\n",
      "scale: 1\n",
      "change: 1\n",
      "better: 1\n",
      "national: 1\n",
      "authorities: 1\n",
      "begin: 1\n",
      "demand: 1\n",
      "higher: 1\n",
      "standard: 1\n",
      "norm: 2\n",
      "naturally: 1\n",
      "applied: 1\n",
      "home: 2\n",
      "commercial: 1\n",
      "suspect: 1\n",
      "potential: 1\n",
      "limited: 1\n",
      "remain: 1\n",
      "compact: 1\n",
      "allows: 1\n",
      "greater: 2\n",
      "freedom: 2\n",
      "designing: 1\n",
      "currently: 1\n",
      "stands: 1\n",
      "appeal: 1\n",
      "packaging: 1\n",
      "allow: 1\n",
      "designers: 1\n",
      "area: 1\n",
      "concerns: 1\n",
      "factor: 1\n",
      "fittings: 1\n",
      "office: 1\n",
      "automobiles: 1\n",
      "regardless: 1\n",
      "sure: 1\n",
      "future: 1\n",
      "posted: 1\n",
      "hacks: 2\n",
      "featured: 1\n",
      "slidertagged: 1\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Load the saved article text\n",
    "try:\n",
    "    with open('article_text.pkl', 'rb') as file:\n",
    "        article_text = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please make sure the file 'article_text.pkl' exists.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Process the text using spaCy pipeline\n",
    "doc = nlp(article_text)\n",
    "\n",
    "# Filter out stopwords, punctuation, and whitespace, and convert tokens to lowercase\n",
    "tokens = [token.text.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "# Count the frequencies of each token\n",
    "token_counter = Counter(tokens)\n",
    "\n",
    "# Get the 5 most frequent tokens\n",
    "most_common_tokens = token_counter.most_common(5)\n",
    "\n",
    "# Print the most common tokens with their frequencies\n",
    "print(\"Most common tokens:\")\n",
    "for token, frequency in most_common_tokens:\n",
    "    print(f\"{token}: {frequency}\")\n",
    "\n",
    "# Print all tokens with their frequencies\n",
    "print(\"\\nAll tokens with frequencies:\")\n",
    "for token, frequency in token_counter.items():\n",
    "    print(f\"{token}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent lemmas (converted to lower case).  Print the common lemmas with an appropriate label.  Additionally, print the lemmas with their frequencies (with appropriate labels). Make sure to remove things we don't care about (punctuation, stopwords, whitespace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_most_common_lemmas(text, n=5):\n",
    "    \"\"\"\n",
    "    Get the n most common lemmas from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        n (int): The number of most common lemmas to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the most common lemmas and their frequencies.\n",
    "    \"\"\"\n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize a Counter to count lemma frequencies\n",
    "    lemma_counter = Counter()\n",
    "\n",
    "    # Iterate over sentences in the document\n",
    "    for sentence in doc.sents:\n",
    "        # Get lemmas from the sentence\n",
    "        lemmas = [token.lemma_.lower() for token in sentence if token.is_alpha]\n",
    "\n",
    "        # Update the lemma counter\n",
    "        lemma_counter.update(lemmas)\n",
    "\n",
    "    # Get the most common lemmas\n",
    "    most_common_lemmas = lemma_counter.most_common(n)\n",
    "\n",
    "    return most_common_lemmas\n",
    "\n",
    "# Get the article text\n",
    "with open(\"article_html.pkl\", \"rb\") as file:\n",
    "    article_html = pickle.load(file)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(article_html, 'html.parser')\n",
    "\n",
    "# Extract text from HTML\n",
    "article_text = soup.get_text()\n",
    "\n",
    "# Get the 5 most common lemmas\n",
    "most_common_lemmas = get_most_common_lemmas(article_text)\n",
    "\n",
    "# Print the most common lemmas with their frequencies\n",
    "print(\"Most common lemmas:\")\n",
    "for lemma, frequency in most_common_lemmas:\n",
    "    print(f\"{lemma}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define the following methods:\n",
    "    * `score_sentence_by_token(sentence, interesting_token)` that takes a sentence and a list of interesting token and returns the number of times that any of the interesting words appear in the sentence divided by the number of words in the sentence\n",
    "    * `score_sentence_by_lemma(sentence, interesting_lemmas)` that takes a sentence and a list of interesting lemmas and returns the number of times that any of the interesting lemmas appear in the sentence divided by the number of words in the sentence\n",
    "    \n",
    "You may find some of the code from the in class notes useful; feel free to use methods (rewrite them in this cell as well).  Test them by showing the score of the first sentence in your article using the frequent tokens and frequent lemmas identified in question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 5 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_sentence_by_token(sentence, interesting_tokens):\n",
    "    \"\"\"\n",
    "    Calculate the score of a sentence based on the occurrence of interesting tokens.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        interesting_tokens (list): List of interesting tokens to search for in the sentence.\n",
    "\n",
    "    Returns:\n",
    "        float: The score of the sentence, calculated as the number of interesting tokens divided by the number of words in the sentence.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # Count the occurrences of interesting tokens in the sentence\n",
    "    interesting_token_count = sum(1 for token in tokens if token.lower() in interesting_tokens)\n",
    "\n",
    "    # Calculate the score\n",
    "    score = interesting_token_count / len(tokens)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def score_sentence_by_lemma(sentence, interesting_lemmas):\n",
    "    \"\"\"\n",
    "    Calculate the score of a sentence based on the occurrence of interesting lemmas.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        interesting_lemmas (list): List of interesting lemmas to search for in the sentence.\n",
    "\n",
    "    Returns:\n",
    "        float: The score of the sentence, calculated as the number of interesting lemmas divided by the number of words in the sentence.\n",
    "    \"\"\"\n",
    "    # Process the sentence using spaCy\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Get lemmas from the sentence\n",
    "    lemmas = [token.lemma_.lower() for token in doc if token.is_alpha]\n",
    "\n",
    "    # Count the occurrences of interesting lemmas in the sentence\n",
    "    interesting_lemma_count = sum(1 for lemma in lemmas if lemma in interesting_lemmas)\n",
    "\n",
    "    # Calculate the score\n",
    "    score = interesting_lemma_count / len(lemmas)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make a list containing the scores (using tokens) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores. From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 6 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_common_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Define the list of interesting tokens (use the most common tokens from question 3)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m interesting_tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m token, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmost_common_tokens\u001b[49m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Get the article text\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_html.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'most_common_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def score_sentence_by_token(sentence, interesting_tokens):\n",
    "    \"\"\"\n",
    "    Calculate the score of a sentence based on the frequency of interesting tokens.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        interesting_tokens (list): A list of interesting tokens.\n",
    "\n",
    "    Returns:\n",
    "        float: The score of the sentence.\n",
    "    \"\"\"\n",
    "    # Tokenize the sentence\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # Count the number of interesting tokens in the sentence\n",
    "    interesting_token_count = sum(1 for token in tokens if token.lower() in interesting_tokens)\n",
    "\n",
    "    # Calculate the score\n",
    "    if len(tokens) > 0:\n",
    "        score = interesting_token_count / len(tokens)\n",
    "    else:\n",
    "        score = 0  # Avoid division by zero\n",
    "\n",
    "    return score\n",
    "\n",
    "# Define the list of interesting tokens (use the most common tokens from question 3)\n",
    "interesting_tokens = [token.lower() for token, _ in most_common_tokens]\n",
    "\n",
    "# Get the article text\n",
    "with open(\"article_html.pkl\", \"rb\") as file:\n",
    "    article_html = pickle.load(file)\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(article_html, 'html.parser')\n",
    "\n",
    "# Extract text from HTML\n",
    "article_text = soup.get_text()\n",
    "\n",
    "# Split the article text into sentences\n",
    "sentences = article_text.split(\".\")\n",
    "\n",
    "# Calculate scores for each sentence\n",
    "sentence_scores = [score_sentence_by_token(sentence, interesting_tokens) for sentence in sentences]\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(sentence_scores, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Sentence Scores based on Token Frequency')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make a list containing the scores (using lemmas) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores.  From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 7 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Which tokens and lexems would be ommitted from the lists generated in questions 3 and 4 if we only wanted to consider nouns as interesting words?  How might we change the code to only consider nouns? Put your answer in this Markdown cell (you can edit it by double clicking it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 8 answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
